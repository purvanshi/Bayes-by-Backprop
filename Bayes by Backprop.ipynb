{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import Parameter\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELBO(nn.Module):\n",
    "    def __init__(self, train_size):\n",
    "        super(ELBO, self).__init__()\n",
    "        self.train_size = train_size\n",
    "\n",
    "    def forward(self, input, target, kl, beta):\n",
    "        assert not target.requires_grad\n",
    "        return F.nll_loss(input, target,reduction='mean')  + (1/self.train_size * kl)\n",
    "\n",
    "\n",
    "# def lr_linear(epoch_num, decay_start, total_epochs, start_value):\n",
    "#     if epoch_num < decay_start:\n",
    "#         return start_value\n",
    "#     return start_value*float(total_epochs-epoch_num)/float(total_epochs-decay_start)\n",
    "\n",
    "\n",
    "def acc(outputs, targets):\n",
    "    return np.mean(outputs.cpu().numpy().argmax(axis=1) == targets.data.cpu().numpy())\n",
    "\n",
    "\n",
    "def calculate_kl(mu_p, sig_p, mu_q, sig_q):\n",
    "    kl = 0.5 * (2 * torch.log(sig_p / sig_q) - 1 + (sig_q / sig_p).pow(2) + ((mu_p - mu_q) / sig_p).pow(2)).sum()\n",
    "    return kl\n",
    "\n",
    "\n",
    "def get_beta(batch_idx, m, beta_type, epoch, num_epochs):\n",
    "    if type(beta_type) is float:\n",
    "        return beta_type\n",
    "\n",
    "    if beta_type == \"Blundell\":\n",
    "        beta = 2 ** (m - (batch_idx + 1)) / (2 ** m - 1)\n",
    "    elif beta_type == \"Soenderby\":\n",
    "        if epoch is None or num_epochs is None:\n",
    "            raise ValueError('Soenderby method requires both epoch and num_epochs to be passed.')\n",
    "        beta = min(epoch / (num_epochs // 4), 1)\n",
    "    elif beta_type == \"Standard\":\n",
    "        beta = 1 / m\n",
    "    else:\n",
    "        beta = 0\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class ModuleWrapper(nn.Module):\n",
    "    \"\"\"Wrapper for nn.Module with support for arbitrary flags and a universal forward pass\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ModuleWrapper, self).__init__()\n",
    "\n",
    "    def set_flag(self, flag_name, value):\n",
    "        setattr(self, flag_name, value)\n",
    "        for m in self.children():\n",
    "            if hasattr(m, 'set_flag'):\n",
    "                m.set_flag(flag_name, value)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for module in self.children():\n",
    "            x = module(x)\n",
    "\n",
    "        kl = 0.0\n",
    "        for module in self.modules():\n",
    "            if hasattr(module, 'kl_loss'):\n",
    "                kl = kl + module.kl_loss()\n",
    "\n",
    "        return x, kl\n",
    "\n",
    "\n",
    "class FlattenLayer(ModuleWrapper):\n",
    "\n",
    "    def __init__(self, num_features):\n",
    "        super(FlattenLayer, self).__init__()\n",
    "        self.num_features = num_features\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(-1, self.num_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BBBLinear(ModuleWrapper):\n",
    "    def __init__(self, in_features, out_features, bias=False, priors=None):\n",
    "        super(BBBLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.use_bias = bias\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        if priors is None:\n",
    "            priors = {\n",
    "                'prior_mu': 0,\n",
    "                'prior_sigma': 0.1,\n",
    "                'posterior_mu_initial': (0, 0.1),\n",
    "                'posterior_rho_initial': (-3, 0.1),\n",
    "            }\n",
    "        self.prior_mu = priors['prior_mu']\n",
    "        self.prior_sigma = priors['prior_sigma']\n",
    "        self.posterior_mu_initial = priors['posterior_mu_initial']\n",
    "        self.posterior_rho_initial = priors['posterior_rho_initial']\n",
    "\n",
    "        self.W_mu = Parameter(torch.empty((out_features, in_features), device=self.device))\n",
    "        self.W_rho = Parameter(torch.empty((out_features, in_features), device=self.device))\n",
    "\n",
    "        if self.use_bias:\n",
    "            self.bias_mu = Parameter(torch.empty((out_features), device=self.device))\n",
    "            self.bias_rho = Parameter(torch.empty((out_features), device=self.device))\n",
    "        else:\n",
    "            self.register_parameter('bias_mu', None)\n",
    "            self.register_parameter('bias_rho', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.W_mu.data.normal_(*self.posterior_mu_initial)\n",
    "        self.W_rho.data.normal_(*self.posterior_rho_initial)\n",
    "\n",
    "        if self.use_bias:\n",
    "            self.bias_mu.data.normal_(*self.posterior_mu_initial)\n",
    "            self.bias_rho.data.normal_(*self.posterior_rho_initial)\n",
    "\n",
    "    def forward(self, input, sample=True):\n",
    "        if self.training or sample:\n",
    "            W_eps = torch.empty(self.W_mu.size()).normal_(0, 1).to(self.device)\n",
    "            self.W_sigma = torch.log1p(torch.exp(self.W_rho))\n",
    "            weight = self.W_mu + W_eps * self.W_sigma\n",
    "\n",
    "            if self.use_bias:\n",
    "                bias_eps = torch.empty(self.bias_mu.size()).normal_(0, 1).to(self.device)\n",
    "                self.bias_sigma = torch.log1p(torch.exp(self.bias_rho))\n",
    "                bias = self.bias_mu + bias_eps * self.bias_sigma\n",
    "            else:\n",
    "                bias = None\n",
    "        else:\n",
    "            weight = self.W_mu\n",
    "            bias = self.bias_mu if self.use_bias else None\n",
    "\n",
    "        return F.linear(input, weight, bias)\n",
    "\n",
    "    def kl_loss(self):\n",
    "        kl = calculate_kl(self.W_mu, self.W_sigma,self.prior_mu, self.prior_sigma)\n",
    "        return kl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(ModuleWrapper):\n",
    "\n",
    "    def __init__(self,priors):\n",
    "        super().__init__()\n",
    "        self.priors = priors\n",
    "        self.flatten = FlattenLayer(4)\n",
    "        self.fc = BBBLinear(4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logmeanexp(x, dim=None, keepdim=False):\n",
    "    \"\"\"Stable computation of log(mean(exp(x))\"\"\"\n",
    "\n",
    "    \n",
    "    if dim is None:\n",
    "        x, dim = x.view(-1), 0\n",
    "    x_max, _ = torch.max(x, dim, keepdim=True)\n",
    "    x = x_max + torch.log(torch.mean(torch.exp(x - x_max), dim, keepdim=True))\n",
    "    return x if keepdim else x.squeeze(dim)\n",
    "\n",
    "# check if dimension is correct\n",
    "\n",
    "# def dimension_check(x, dim=None, keepdim=False):\n",
    "#     if dim is None:\n",
    "#         x, dim = x.view(-1), 0\n",
    "\n",
    "#     return x if keepdim else x.squeeze(dim)\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, lr):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def save_array_to_file(numpy_array, filename):\n",
    "    file = open(filename, 'a')\n",
    "    shape = \" \".join(map(str, numpy_array.shape))\n",
    "    np.savetxt(file, numpy_array.flatten(), newline=\" \", fmt=\"%.3f\")\n",
    "    file.write(\"\\n\")\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, optimizer, criterion, trainloader, num_ens=1, beta_type=0.1, epoch=None, num_epochs=None):\n",
    "    net.train()\n",
    "    training_loss = 0.0\n",
    "    accs = []\n",
    "    kl_list = []\n",
    "    for i, (inputs, labels) in enumerate(trainloader, 1):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = torch.zeros(inputs.shape[0],2, num_ens).to(device)\n",
    "\n",
    "        kl = 0.0\n",
    "        for j in range(num_ens):\n",
    "            net_out, _kl = net(inputs.float())\n",
    "            kl += _kl\n",
    "            outputs[:, :, j] = F.log_softmax(net_out, dim=1)\n",
    "        \n",
    "        kl = kl / num_ens\n",
    "        kl_list.append(kl.item())\n",
    "        log_outputs = torch.mean(outputs, dim=2)\n",
    "\n",
    "        beta =get_beta(i-1, len(trainloader), beta_type, epoch, num_epochs)\n",
    "        loss = criterion(log_outputs, labels, kl, beta)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        accs.append(acc(log_outputs.data, labels))\n",
    "        training_loss += loss.cpu().data.numpy()\n",
    "    return training_loss/len(trainloader), np.mean(accs), np.mean(kl_list)\n",
    "\n",
    "\n",
    "def validate_model(net, criterion, validloader, num_ens=1, beta_type=0.1, epoch=None, num_epochs=None):\n",
    "    \"\"\"Calculate ensemble accuracy and NLL Loss\"\"\"\n",
    "    net.train()\n",
    "    valid_loss = 0.0\n",
    "    accs = []\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(validloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = torch.zeros(inputs.shape[0], 2, num_ens).to(device)\n",
    "        kl = 0.0\n",
    "        for j in range(num_ens):\n",
    "            net_out, _kl = net(inputs.float())\n",
    "            kl += _kl\n",
    "            outputs[:, :, j] = F.log_softmax(net_out, dim=1).data\n",
    "\n",
    "        log_outputs = torch.mean(outputs, dim=2)\n",
    "\n",
    "        beta = get_beta(i-1, len(validloader), beta_type, epoch, num_epochs)\n",
    "        valid_loss += criterion(log_outputs, labels, kl, beta).item()\n",
    "        accs.append(acc(log_outputs, labels))\n",
    "\n",
    "    return valid_loss/len(validloader), np.mean(accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Configuration file for Bayesian ###############\n",
    "layer_type = 'lrt'  # 'bbb' or 'lrt'\n",
    "activation_type = 'softplus'  # 'softplus' or 'relu'\n",
    "priors={\n",
    "    'prior_mu': 0,\n",
    "    'prior_sigma': 0.1,\n",
    "    'posterior_mu_initial': (0, 0.1),  # (mean, std) normal_\n",
    "    'posterior_rho_initial': (-1, 0.1),  # (mean, std) normal_\n",
    "}\n",
    "\n",
    "n_epochs = 100\n",
    "lr_start = 0.01\n",
    "num_workers = 4\n",
    "valid_size = 0.2\n",
    "batch_size = 1000\n",
    "train_ens = 10\n",
    "valid_ens = 10\n",
    "beta_type = 'Blundell'  # 'Blundell', 'Standard', etc. Use float for const value\n",
    "record_mean_var = True\n",
    "recording_freq_per_epoch = 1\n",
    "record_layers = ['fc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel(net_type,priors):\n",
    "    if (net_type == 'Net'):\n",
    "        return Net(priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "test\n",
      "Epoch: 0 \tTraining Loss: 0.6518 \tTraining Accuracy: 0.6770 \tValidation Loss: 0.7503 \tValidation Accuracy: 0.6350 \ttrain_kl_div: 22.8075\n",
      "fc.W_mu tensor([[-0.1073, -0.1939,  0.0089, -0.0087],\n",
      "        [-0.0805,  0.0494, -0.0917, -0.0457]])\n",
      "fc.W_rho tensor([[-2.9046, -2.9496, -2.9447, -2.9470],\n",
      "        [-3.1022, -3.0272, -2.9980, -3.0925]])\n",
      "Validation loss decreased (inf --> 0.750336).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 1 \tTraining Loss: 0.6469 \tTraining Accuracy: 0.6975 \tValidation Loss: 0.7294 \tValidation Accuracy: 0.7800 \ttrain_kl_div: 20.7397\n",
      "fc.W_mu tensor([[-0.0921, -0.2047,  0.0096, -0.0179],\n",
      "        [-0.0948,  0.0617, -0.0722, -0.0264]])\n",
      "fc.W_rho tensor([[-2.8891, -2.9308, -2.9247, -2.9271],\n",
      "        [-3.0843, -3.0093, -2.9785, -3.0729]])\n",
      "Validation loss decreased (0.750336 --> 0.729381).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 2 \tTraining Loss: 0.6519 \tTraining Accuracy: 0.6870 \tValidation Loss: 0.7293 \tValidation Accuracy: 0.7925 \ttrain_kl_div: 20.2836\n",
      "fc.W_mu tensor([[-0.0773, -0.2164,  0.0168, -0.0238],\n",
      "        [-0.1085,  0.0745, -0.0535, -0.0083]])\n",
      "fc.W_rho tensor([[-2.8867, -2.9123, -2.9049, -2.9072],\n",
      "        [-3.0670, -2.9976, -2.9596, -3.0538]])\n",
      "Validation loss decreased (0.729381 --> 0.729295).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 3 \tTraining Loss: 0.6187 \tTraining Accuracy: 0.8875 \tValidation Loss: 0.7168 \tValidation Accuracy: 0.8625 \ttrain_kl_div: 20.6082\n",
      "fc.W_mu tensor([[-0.0628, -0.2283,  0.0258, -0.0260],\n",
      "        [-0.1219,  0.0876, -0.0365,  0.0077]])\n",
      "fc.W_rho tensor([[-2.8786, -2.8937, -2.8853, -2.8874],\n",
      "        [-3.0493, -2.9924, -2.9415, -3.0352]])\n",
      "Validation loss decreased (0.729295 --> 0.716803).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 4 \tTraining Loss: 0.6276 \tTraining Accuracy: 0.7775 \tValidation Loss: 0.7028 \tValidation Accuracy: 0.9025 \ttrain_kl_div: 21.4537\n",
      "fc.W_mu tensor([[-0.0485, -0.2403,  0.0280, -0.0248],\n",
      "        [-0.1352,  0.1006, -0.0216,  0.0207]])\n",
      "fc.W_rho tensor([[-2.8776, -2.8758, -2.8656, -2.8676],\n",
      "        [-3.0348, -2.9849, -2.9244, -3.0168]])\n",
      "Validation loss decreased (0.716803 --> 0.702784).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 5 \tTraining Loss: 0.5989 \tTraining Accuracy: 0.9080 \tValidation Loss: 0.7061 \tValidation Accuracy: 0.8325 \ttrain_kl_div: 22.6211\n",
      "fc.W_mu tensor([[-0.0343, -0.2523,  0.0252, -0.0212],\n",
      "        [-0.1482,  0.1136, -0.0095,  0.0299]])\n",
      "fc.W_rho tensor([[-2.8751, -2.8582, -2.8463, -2.8481],\n",
      "        [-3.0187, -2.9731, -2.9080, -2.9987]])\n",
      "train\n",
      "test\n",
      "Epoch: 6 \tTraining Loss: 0.5945 \tTraining Accuracy: 0.9185 \tValidation Loss: 0.7007 \tValidation Accuracy: 0.9350 \ttrain_kl_div: 23.9190\n",
      "fc.W_mu tensor([[-0.0203, -0.2643,  0.0217, -0.0164],\n",
      "        [-0.1611,  0.1265, -0.0006,  0.0352]])\n",
      "fc.W_rho tensor([[-2.8732, -2.8401, -2.8272, -2.8290],\n",
      "        [-3.0014, -2.9594, -2.8924, -2.9807]])\n",
      "Validation loss decreased (0.702784 --> 0.700733).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 7 \tTraining Loss: 0.5898 \tTraining Accuracy: 0.9390 \tValidation Loss: 0.7016 \tValidation Accuracy: 0.9225 \ttrain_kl_div: 25.3261\n",
      "fc.W_mu tensor([[-0.0064, -0.2762,  0.0222, -0.0122],\n",
      "        [-0.1738,  0.1392,  0.0048,  0.0370]])\n",
      "fc.W_rho tensor([[-2.8707, -2.8223, -2.8084, -2.8104],\n",
      "        [-2.9841, -2.9448, -2.8776, -2.9627]])\n",
      "train\n",
      "test\n",
      "Epoch: 8 \tTraining Loss: 0.5723 \tTraining Accuracy: 0.9410 \tValidation Loss: 0.7007 \tValidation Accuracy: 0.9475 \ttrain_kl_div: 26.8384\n",
      "fc.W_mu tensor([[ 0.0073, -0.2880,  0.0248, -0.0092],\n",
      "        [-0.1863,  0.1519,  0.0072,  0.0360]])\n",
      "fc.W_rho tensor([[-2.8671, -2.8039, -2.7898, -2.7924],\n",
      "        [-2.9678, -2.9301, -2.8631, -2.9446]])\n",
      "train\n",
      "test\n",
      "Epoch: 9 \tTraining Loss: 0.5622 \tTraining Accuracy: 0.9535 \tValidation Loss: 0.7068 \tValidation Accuracy: 0.9700 \ttrain_kl_div: 28.3897\n",
      "fc.W_mu tensor([[ 0.0209, -0.2996,  0.0305, -0.0084],\n",
      "        [-0.1987,  0.1643,  0.0065,  0.0332]])\n",
      "fc.W_rho tensor([[-2.8671, -2.7842, -2.7717, -2.7748],\n",
      "        [-2.9496, -2.9148, -2.8493, -2.9267]])\n",
      "train\n",
      "test\n",
      "Epoch: 10 \tTraining Loss: 0.5507 \tTraining Accuracy: 0.9610 \tValidation Loss: 0.6778 \tValidation Accuracy: 0.9725 \ttrain_kl_div: 29.9286\n",
      "fc.W_mu tensor([[ 0.0343, -0.3111,  0.0337, -0.0093],\n",
      "        [-0.2109,  0.1765,  0.0038,  0.0290]])\n",
      "fc.W_rho tensor([[-2.8676, -2.7639, -2.7540, -2.7577],\n",
      "        [-2.9304, -2.8978, -2.8359, -2.9091]])\n",
      "Validation loss decreased (0.700733 --> 0.677849).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 11 \tTraining Loss: 0.5476 \tTraining Accuracy: 0.9560 \tValidation Loss: 0.6941 \tValidation Accuracy: 0.9700 \ttrain_kl_div: 31.4195\n",
      "fc.W_mu tensor([[ 0.0476, -0.3225,  0.0333, -0.0117],\n",
      "        [-0.2229,  0.1886, -0.0004,  0.0243]])\n",
      "fc.W_rho tensor([[-2.8706, -2.7431, -2.7365, -2.7409],\n",
      "        [-2.9107, -2.8791, -2.8228, -2.8918]])\n",
      "train\n",
      "test\n",
      "Epoch: 12 \tTraining Loss: 0.5462 \tTraining Accuracy: 0.9630 \tValidation Loss: 0.6792 \tValidation Accuracy: 0.9850 \ttrain_kl_div: 32.8967\n",
      "fc.W_mu tensor([[ 0.0607, -0.3338,  0.0322, -0.0153],\n",
      "        [-0.2348,  0.2004, -0.0057,  0.0198]])\n",
      "fc.W_rho tensor([[-2.8718, -2.7226, -2.7192, -2.7245],\n",
      "        [-2.8923, -2.8600, -2.8103, -2.8752]])\n",
      "train\n",
      "test\n",
      "Epoch: 13 \tTraining Loss: 0.5233 \tTraining Accuracy: 0.9690 \tValidation Loss: 0.6797 \tValidation Accuracy: 0.9900 \ttrain_kl_div: 34.4103\n",
      "fc.W_mu tensor([[ 0.0736, -0.3449,  0.0293, -0.0186],\n",
      "        [-0.2466,  0.2121, -0.0113,  0.0154]])\n",
      "fc.W_rho tensor([[-2.8723, -2.7022, -2.7023, -2.7085],\n",
      "        [-2.8727, -2.8399, -2.7980, -2.8589]])\n",
      "train\n",
      "test\n",
      "Epoch: 14 \tTraining Loss: 0.5160 \tTraining Accuracy: 0.9690 \tValidation Loss: 0.6767 \tValidation Accuracy: 0.9825 \ttrain_kl_div: 35.8947\n",
      "fc.W_mu tensor([[ 0.0863, -0.3559,  0.0294, -0.0208],\n",
      "        [-0.2581,  0.2236, -0.0172,  0.0115]])\n",
      "fc.W_rho tensor([[-2.8702, -2.6817, -2.6862, -2.6928],\n",
      "        [-2.8525, -2.8187, -2.7860, -2.8432]])\n",
      "Validation loss decreased (0.677849 --> 0.676714).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 15 \tTraining Loss: 0.5210 \tTraining Accuracy: 0.9685 \tValidation Loss: 0.6776 \tValidation Accuracy: 0.9825 \ttrain_kl_div: 37.3445\n",
      "fc.W_mu tensor([[ 0.0988, -0.3668,  0.0306, -0.0218],\n",
      "        [-0.2696,  0.2349, -0.0228,  0.0083]])\n",
      "fc.W_rho tensor([[-2.8681, -2.6611, -2.6707, -2.6779],\n",
      "        [-2.8320, -2.7975, -2.7743, -2.8282]])\n",
      "train\n",
      "test\n",
      "Epoch: 16 \tTraining Loss: 0.5177 \tTraining Accuracy: 0.9715 \tValidation Loss: 0.6923 \tValidation Accuracy: 0.9775 \ttrain_kl_div: 38.7911\n",
      "fc.W_mu tensor([[ 0.1111, -0.3776,  0.0278, -0.0223],\n",
      "        [-0.2809,  0.2461, -0.0270,  0.0062]])\n",
      "fc.W_rho tensor([[-2.8670, -2.6404, -2.6555, -2.6635],\n",
      "        [-2.8120, -2.7777, -2.7627, -2.8139]])\n",
      "train\n",
      "test\n",
      "Epoch: 17 \tTraining Loss: 0.5011 \tTraining Accuracy: 0.9740 \tValidation Loss: 0.6929 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 40.2291\n",
      "fc.W_mu tensor([[ 0.1233, -0.3883,  0.0273, -0.0228],\n",
      "        [-0.2920,  0.2571, -0.0304,  0.0052]])\n",
      "fc.W_rho tensor([[-2.8649, -2.6197, -2.6409, -2.6496],\n",
      "        [-2.7906, -2.7587, -2.7513, -2.7997]])\n",
      "train\n",
      "test\n",
      "Epoch: 18 \tTraining Loss: 0.4995 \tTraining Accuracy: 0.9800 \tValidation Loss: 0.6781 \tValidation Accuracy: 0.9825 \ttrain_kl_div: 41.6285\n",
      "fc.W_mu tensor([[ 0.1352, -0.3989,  0.0286, -0.0224],\n",
      "        [-0.3031,  0.2681, -0.0329,  0.0051]])\n",
      "fc.W_rho tensor([[-2.8599, -2.5992, -2.6267, -2.6363],\n",
      "        [-2.7703, -2.7392, -2.7400, -2.7859]])\n",
      "train\n",
      "test\n",
      "Epoch: 19 \tTraining Loss: 0.4847 \tTraining Accuracy: 0.9840 \tValidation Loss: 0.6762 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 42.9746\n",
      "fc.W_mu tensor([[ 0.1469, -0.4094,  0.0277, -0.0220],\n",
      "        [-0.3139,  0.2789, -0.0340,  0.0059]])\n",
      "fc.W_rho tensor([[-2.8504, -2.5786, -2.6128, -2.6237],\n",
      "        [-2.7490, -2.7200, -2.7287, -2.7725]])\n",
      "Validation loss decreased (0.676714 --> 0.676173).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 20 \tTraining Loss: 0.4955 \tTraining Accuracy: 0.9785 \tValidation Loss: 0.6829 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 44.2258\n",
      "fc.W_mu tensor([[ 0.1585, -0.4199,  0.0257, -0.0229],\n",
      "        [-0.3246,  0.2896, -0.0339,  0.0078]])\n",
      "fc.W_rho tensor([[-2.8398, -2.5582, -2.5991, -2.6117],\n",
      "        [-2.7300, -2.7018, -2.7174, -2.7597]])\n",
      "train\n",
      "test\n",
      "Epoch: 21 \tTraining Loss: 0.4833 \tTraining Accuracy: 0.9810 \tValidation Loss: 0.6853 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 45.4882\n",
      "fc.W_mu tensor([[ 0.1698, -0.4303,  0.0232, -0.0248],\n",
      "        [-0.3353,  0.3002, -0.0328,  0.0107]])\n",
      "fc.W_rho tensor([[-2.8306, -2.5383, -2.5859, -2.6003],\n",
      "        [-2.7089, -2.6853, -2.7061, -2.7473]])\n",
      "train\n",
      "test\n",
      "Epoch: 22 \tTraining Loss: 0.4731 \tTraining Accuracy: 0.9840 \tValidation Loss: 0.6793 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 46.7325\n",
      "fc.W_mu tensor([[ 0.1810, -0.4407,  0.0234, -0.0259],\n",
      "        [-0.3458,  0.3106, -0.0311,  0.0135]])\n",
      "fc.W_rho tensor([[-2.8206, -2.5182, -2.5734, -2.5891],\n",
      "        [-2.6887, -2.6689, -2.6950, -2.7352]])\n",
      "train\n",
      "test\n",
      "Epoch: 23 \tTraining Loss: 0.4593 \tTraining Accuracy: 0.9860 \tValidation Loss: 0.6716 \tValidation Accuracy: 0.9900 \ttrain_kl_div: 47.9023\n",
      "fc.W_mu tensor([[ 0.1920, -0.4509,  0.0263, -0.0255],\n",
      "        [-0.3562,  0.3209, -0.0292,  0.0156]])\n",
      "fc.W_rho tensor([[-2.8083, -2.4981, -2.5616, -2.5780],\n",
      "        [-2.6680, -2.6501, -2.6840, -2.7235]])\n",
      "Validation loss decreased (0.676173 --> 0.671632).  Saving model ...\n",
      "train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Epoch: 24 \tTraining Loss: 0.4549 \tTraining Accuracy: 0.9840 \tValidation Loss: 0.6759 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 48.9048\n",
      "fc.W_mu tensor([[ 0.2027, -0.4609,  0.0331, -0.0246],\n",
      "        [-0.3664,  0.3310, -0.0278,  0.0174]])\n",
      "fc.W_rho tensor([[-2.7937, -2.4784, -2.5505, -2.5671],\n",
      "        [-2.6461, -2.6295, -2.6734, -2.7122]])\n",
      "train\n",
      "test\n",
      "Epoch: 25 \tTraining Loss: 0.4487 \tTraining Accuracy: 0.9865 \tValidation Loss: 0.6869 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 49.7897\n",
      "fc.W_mu tensor([[ 0.2133, -0.4709,  0.0395, -0.0246],\n",
      "        [-0.3766,  0.3410, -0.0266,  0.0193]])\n",
      "fc.W_rho tensor([[-2.7779, -2.4583, -2.5400, -2.5566],\n",
      "        [-2.6246, -2.6079, -2.6629, -2.7011]])\n",
      "train\n",
      "test\n",
      "Epoch: 26 \tTraining Loss: 0.4469 \tTraining Accuracy: 0.9855 \tValidation Loss: 0.6559 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 50.5575\n",
      "fc.W_mu tensor([[ 0.2238, -0.4806,  0.0394, -0.0248],\n",
      "        [-0.3867,  0.3507, -0.0251,  0.0209]])\n",
      "fc.W_rho tensor([[-2.7656, -2.4376, -2.5294, -2.5462],\n",
      "        [-2.6027, -2.5853, -2.6527, -2.6903]])\n",
      "Validation loss decreased (0.671632 --> 0.655886).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 27 \tTraining Loss: 0.4386 \tTraining Accuracy: 0.9895 \tValidation Loss: 0.6699 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 51.1773\n",
      "fc.W_mu tensor([[ 0.2341, -0.4903,  0.0369, -0.0247],\n",
      "        [-0.3967,  0.3604, -0.0239,  0.0219]])\n",
      "fc.W_rho tensor([[-2.7520, -2.4165, -2.5191, -2.5362],\n",
      "        [-2.5789, -2.5637, -2.6427, -2.6800]])\n",
      "train\n",
      "test\n",
      "Epoch: 28 \tTraining Loss: 0.4278 \tTraining Accuracy: 0.9860 \tValidation Loss: 0.6571 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 51.6960\n",
      "fc.W_mu tensor([[ 0.2441, -0.4999,  0.0334, -0.0241],\n",
      "        [-0.4066,  0.3699, -0.0231,  0.0223]])\n",
      "fc.W_rho tensor([[-2.7411, -2.3950, -2.5090, -2.5263],\n",
      "        [-2.5536, -2.5428, -2.6332, -2.6699]])\n",
      "train\n",
      "test\n",
      "Epoch: 29 \tTraining Loss: 0.4173 \tTraining Accuracy: 0.9880 \tValidation Loss: 0.6569 \tValidation Accuracy: 0.9950 \ttrain_kl_div: 52.0919\n",
      "fc.W_mu tensor([[ 0.2540, -0.5094,  0.0290, -0.0232],\n",
      "        [-0.4163,  0.3793, -0.0223,  0.0221]])\n",
      "fc.W_rho tensor([[-2.7258, -2.3731, -2.4992, -2.5165],\n",
      "        [-2.5280, -2.5211, -2.6238, -2.6600]])\n",
      "train\n",
      "test\n",
      "Epoch: 30 \tTraining Loss: 0.4136 \tTraining Accuracy: 0.9880 \tValidation Loss: 0.6560 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 52.3249\n",
      "fc.W_mu tensor([[ 0.2637, -0.5188,  0.0288, -0.0234],\n",
      "        [-0.4259,  0.3886, -0.0223,  0.0220]])\n",
      "fc.W_rho tensor([[-2.7067, -2.3509, -2.4902, -2.5075],\n",
      "        [-2.5034, -2.4985, -2.6148, -2.6503]])\n",
      "train\n",
      "test\n",
      "Epoch: 31 \tTraining Loss: 0.4084 \tTraining Accuracy: 0.9900 \tValidation Loss: 0.6378 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 52.4497\n",
      "fc.W_mu tensor([[ 0.2733, -0.5280,  0.0304, -0.0240],\n",
      "        [-0.4354,  0.3977, -0.0226,  0.0219]])\n",
      "fc.W_rho tensor([[-2.6844, -2.3285, -2.4822, -2.4991],\n",
      "        [-2.4800, -2.4752, -2.6062, -2.6410]])\n",
      "Validation loss decreased (0.655886 --> 0.637807).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 32 \tTraining Loss: 0.4107 \tTraining Accuracy: 0.9860 \tValidation Loss: 0.6379 \tValidation Accuracy: 0.9950 \ttrain_kl_div: 52.4984\n",
      "fc.W_mu tensor([[ 0.2828, -0.5371,  0.0322, -0.0248],\n",
      "        [-0.4450,  0.4067, -0.0231,  0.0216]])\n",
      "fc.W_rho tensor([[-2.6620, -2.3061, -2.4743, -2.4912],\n",
      "        [-2.4596, -2.4508, -2.5981, -2.6317]])\n",
      "train\n",
      "test\n",
      "Epoch: 33 \tTraining Loss: 0.3888 \tTraining Accuracy: 0.9910 \tValidation Loss: 0.6357 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 52.4848\n",
      "fc.W_mu tensor([[ 0.2920, -0.5461,  0.0337, -0.0256],\n",
      "        [-0.4543,  0.4155, -0.0236,  0.0213]])\n",
      "fc.W_rho tensor([[-2.6365, -2.2839, -2.4669, -2.4838],\n",
      "        [-2.4370, -2.4266, -2.5902, -2.6228]])\n",
      "Validation loss decreased (0.637807 --> 0.635657).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 34 \tTraining Loss: 0.3937 \tTraining Accuracy: 0.9885 \tValidation Loss: 0.6317 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 52.3391\n",
      "fc.W_mu tensor([[ 0.3012, -0.5551,  0.0363, -0.0265],\n",
      "        [-0.4636,  0.4244, -0.0244,  0.0210]])\n",
      "fc.W_rho tensor([[-2.6097, -2.2611, -2.4597, -2.4769],\n",
      "        [-2.4156, -2.4035, -2.5824, -2.6143]])\n",
      "Validation loss decreased (0.635657 --> 0.631745).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 35 \tTraining Loss: 0.4035 \tTraining Accuracy: 0.9860 \tValidation Loss: 0.6216 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 52.1666\n",
      "fc.W_mu tensor([[ 0.3102, -0.5641,  0.0393, -0.0275],\n",
      "        [-0.4729,  0.4331, -0.0256,  0.0209]])\n",
      "fc.W_rho tensor([[-2.5846, -2.2387, -2.4525, -2.4705],\n",
      "        [-2.3938, -2.3818, -2.5747, -2.6061]])\n",
      "Validation loss decreased (0.631745 --> 0.621628).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 36 \tTraining Loss: 0.3803 \tTraining Accuracy: 0.9870 \tValidation Loss: 0.6306 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 52.0359\n",
      "fc.W_mu tensor([[ 0.3192, -0.5730,  0.0385, -0.0292],\n",
      "        [-0.4821,  0.4419, -0.0263,  0.0212]])\n",
      "fc.W_rho tensor([[-2.5613, -2.2163, -2.4457, -2.4644],\n",
      "        [-2.3710, -2.3614, -2.5671, -2.5982]])\n",
      "train\n",
      "test\n",
      "Epoch: 37 \tTraining Loss: 0.3909 \tTraining Accuracy: 0.9865 \tValidation Loss: 0.6339 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 51.8501\n",
      "fc.W_mu tensor([[ 0.3282, -0.5818,  0.0364, -0.0300],\n",
      "        [-0.4912,  0.4505, -0.0270,  0.0213]])\n",
      "fc.W_rho tensor([[-2.5400, -2.1944, -2.4390, -2.4583],\n",
      "        [-2.3488, -2.3402, -2.5596, -2.5906]])\n",
      "train\n",
      "test\n",
      "Epoch: 38 \tTraining Loss: 0.3774 \tTraining Accuracy: 0.9865 \tValidation Loss: 0.6124 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 51.6582\n",
      "fc.W_mu tensor([[ 0.3370, -0.5906,  0.0330, -0.0298],\n",
      "        [-0.5003,  0.4591, -0.0273,  0.0211]])\n",
      "fc.W_rho tensor([[-2.5184, -2.1740, -2.4325, -2.4528],\n",
      "        [-2.3259, -2.3183, -2.5524, -2.5831]])\n",
      "Validation loss decreased (0.621628 --> 0.612418).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 39 \tTraining Loss: 0.3583 \tTraining Accuracy: 0.9890 \tValidation Loss: 0.6065 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 51.4168\n",
      "fc.W_mu tensor([[ 0.3457, -0.5993,  0.0290, -0.0290],\n",
      "        [-0.5093,  0.4676, -0.0273,  0.0207]])\n",
      "fc.W_rho tensor([[-2.4949, -2.1544, -2.4266, -2.4473],\n",
      "        [-2.3033, -2.2947, -2.5451, -2.5756]])\n",
      "Validation loss decreased (0.612418 --> 0.606461).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 40 \tTraining Loss: 0.3676 \tTraining Accuracy: 0.9915 \tValidation Loss: 0.5930 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 51.0508\n",
      "fc.W_mu tensor([[ 0.3543, -0.6079,  0.0252, -0.0278],\n",
      "        [-0.5182,  0.4760, -0.0269,  0.0203]])\n",
      "fc.W_rho tensor([[-2.4708, -2.1359, -2.4209, -2.4419],\n",
      "        [-2.2800, -2.2703, -2.5379, -2.5680]])\n",
      "Validation loss decreased (0.606461 --> 0.592959).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 41 \tTraining Loss: 0.3553 \tTraining Accuracy: 0.9895 \tValidation Loss: 0.5863 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 50.6856\n",
      "fc.W_mu tensor([[ 0.3629, -0.6164,  0.0241, -0.0271],\n",
      "        [-0.5271,  0.4843, -0.0265,  0.0202]])\n",
      "fc.W_rho tensor([[-2.4457, -2.1172, -2.4159, -2.4366],\n",
      "        [-2.2592, -2.2459, -2.5311, -2.5604]])\n",
      "Validation loss decreased (0.592959 --> 0.586263).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 42 \tTraining Loss: 0.3580 \tTraining Accuracy: 0.9900 \tValidation Loss: 0.6035 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 50.3117\n",
      "fc.W_mu tensor([[ 0.3714, -0.6248,  0.0249, -0.0271],\n",
      "        [-0.5360,  0.4925, -0.0259,  0.0205]])\n",
      "fc.W_rho tensor([[-2.4232, -2.0976, -2.4113, -2.4318],\n",
      "        [-2.2381, -2.2214, -2.5244, -2.5534]])\n",
      "train\n",
      "test\n",
      "Epoch: 43 \tTraining Loss: 0.3580 \tTraining Accuracy: 0.9905 \tValidation Loss: 0.5853 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 49.9312\n",
      "fc.W_mu tensor([[ 0.3799, -0.6331,  0.0296, -0.0270],\n",
      "        [-0.5448,  0.5007, -0.0258,  0.0207]])\n",
      "fc.W_rho tensor([[-2.3987, -2.0781, -2.4076, -2.4270],\n",
      "        [-2.2181, -2.1986, -2.5180, -2.5471]])\n",
      "Validation loss decreased (0.586263 --> 0.585324).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 44 \tTraining Loss: 0.3632 \tTraining Accuracy: 0.9895 \tValidation Loss: 0.5827 \tValidation Accuracy: 0.9950 \ttrain_kl_div: 49.5854\n",
      "fc.W_mu tensor([[ 0.3884, -0.6416,  0.0351, -0.0271],\n",
      "        [-0.5536,  0.5089, -0.0259,  0.0211]])\n",
      "fc.W_rho tensor([[-2.3750, -2.0597, -2.4035, -2.4224],\n",
      "        [-2.1975, -2.1782, -2.5118, -2.5409]])\n",
      "Validation loss decreased (0.585324 --> 0.582666).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 45 \tTraining Loss: 0.3728 \tTraining Accuracy: 0.9860 \tValidation Loss: 0.5743 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 49.3480\n",
      "fc.W_mu tensor([[ 0.3968, -0.6502,  0.0402, -0.0274],\n",
      "        [-0.5624,  0.5173, -0.0263,  0.0215]])\n",
      "fc.W_rho tensor([[-2.3520, -2.0429, -2.3995, -2.4181],\n",
      "        [-2.1793, -2.1610, -2.5060, -2.5348]])\n",
      "Validation loss decreased (0.582666 --> 0.574278).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 46 \tTraining Loss: 0.3538 \tTraining Accuracy: 0.9915 \tValidation Loss: 0.5665 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 49.2707\n",
      "fc.W_mu tensor([[ 0.4052, -0.6589,  0.0451, -0.0267],\n",
      "        [-0.5711,  0.5259, -0.0272,  0.0214]])\n",
      "fc.W_rho tensor([[-2.3317, -2.0274, -2.3959, -2.4142],\n",
      "        [-2.1590, -2.1462, -2.5007, -2.5289]])\n",
      "Validation loss decreased (0.574278 --> 0.566471).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 47 \tTraining Loss: 0.3343 \tTraining Accuracy: 0.9925 \tValidation Loss: 0.5625 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 49.2217\n",
      "fc.W_mu tensor([[ 0.4134, -0.6676,  0.0445, -0.0251],\n",
      "        [-0.5797,  0.5344, -0.0277,  0.0208]])\n",
      "fc.W_rho tensor([[-2.3095, -2.0121, -2.3918, -2.4103],\n",
      "        [-2.1383, -2.1320, -2.4956, -2.5230]])\n",
      "Validation loss decreased (0.566471 --> 0.562540).  Saving model ...\n",
      "train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Epoch: 48 \tTraining Loss: 0.3364 \tTraining Accuracy: 0.9870 \tValidation Loss: 0.5613 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 49.1051\n",
      "fc.W_mu tensor([[ 0.4218, -0.6761,  0.0403, -0.0240],\n",
      "        [-0.5884,  0.5427, -0.0279,  0.0203]])\n",
      "fc.W_rho tensor([[-2.2923, -1.9953, -2.3875, -2.4064],\n",
      "        [-2.1186, -2.1168, -2.4909, -2.5169]])\n",
      "Validation loss decreased (0.562540 --> 0.561344).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 49 \tTraining Loss: 0.3286 \tTraining Accuracy: 0.9905 \tValidation Loss: 0.5625 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 48.9205\n",
      "fc.W_mu tensor([[ 0.4300, -0.6844,  0.0310, -0.0238],\n",
      "        [-0.5970,  0.5508, -0.0273,  0.0202]])\n",
      "fc.W_rho tensor([[-2.2739, -1.9778, -2.3830, -2.4028],\n",
      "        [-2.0979, -2.1004, -2.4863, -2.5109]])\n",
      "train\n",
      "test\n",
      "Epoch: 50 \tTraining Loss: 0.3232 \tTraining Accuracy: 0.9885 \tValidation Loss: 0.5517 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 48.6461\n",
      "fc.W_mu tensor([[ 0.4382, -0.6925,  0.0232, -0.0240],\n",
      "        [-0.6055,  0.5588, -0.0266,  0.0203]])\n",
      "fc.W_rho tensor([[-2.2564, -1.9601, -2.3788, -2.3991],\n",
      "        [-2.0770, -2.0835, -2.4819, -2.5050]])\n",
      "Validation loss decreased (0.561344 --> 0.551710).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 51 \tTraining Loss: 0.3409 \tTraining Accuracy: 0.9865 \tValidation Loss: 0.5305 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 48.3701\n",
      "fc.W_mu tensor([[ 0.4464, -0.7006,  0.0210, -0.0244],\n",
      "        [-0.6142,  0.5667, -0.0263,  0.0204]])\n",
      "fc.W_rho tensor([[-2.2417, -1.9428, -2.3759, -2.3954],\n",
      "        [-2.0583, -2.0658, -2.4778, -2.4993]])\n",
      "Validation loss decreased (0.551710 --> 0.530451).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 52 \tTraining Loss: 0.3222 \tTraining Accuracy: 0.9885 \tValidation Loss: 0.5425 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 48.2012\n",
      "fc.W_mu tensor([[ 0.4547, -0.7086,  0.0257, -0.0253],\n",
      "        [-0.6228,  0.5745, -0.0269,  0.0208]])\n",
      "fc.W_rho tensor([[-2.2273, -1.9261, -2.3737, -2.3925],\n",
      "        [-2.0408, -2.0467, -2.4735, -2.4937]])\n",
      "train\n",
      "test\n",
      "Epoch: 53 \tTraining Loss: 0.3389 \tTraining Accuracy: 0.9825 \tValidation Loss: 0.5554 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 48.0835\n",
      "fc.W_mu tensor([[ 0.4631, -0.7164,  0.0343, -0.0270],\n",
      "        [-0.6316,  0.5822, -0.0280,  0.0216]])\n",
      "fc.W_rho tensor([[-2.2181, -1.9093, -2.3721, -2.3898],\n",
      "        [-2.0263, -2.0269, -2.4693, -2.4881]])\n",
      "train\n",
      "test\n",
      "Epoch: 54 \tTraining Loss: 0.3111 \tTraining Accuracy: 0.9880 \tValidation Loss: 0.5197 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 48.0722\n",
      "fc.W_mu tensor([[ 0.4713, -0.7242,  0.0428, -0.0285],\n",
      "        [-0.6402,  0.5898, -0.0293,  0.0224]])\n",
      "fc.W_rho tensor([[-2.2043, -1.8924, -2.3705, -2.3873],\n",
      "        [-2.0116, -2.0080, -2.4653, -2.4828]])\n",
      "Validation loss decreased (0.530451 --> 0.519728).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 55 \tTraining Loss: 0.3137 \tTraining Accuracy: 0.9915 \tValidation Loss: 0.5567 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 47.9531\n",
      "fc.W_mu tensor([[ 0.4794, -0.7320,  0.0441, -0.0299],\n",
      "        [-0.6487,  0.5974, -0.0295,  0.0232]])\n",
      "fc.W_rho tensor([[-2.1879, -1.8758, -2.3683, -2.3850],\n",
      "        [-1.9965, -1.9900, -2.4612, -2.4778]])\n",
      "train\n",
      "test\n",
      "Epoch: 56 \tTraining Loss: 0.2981 \tTraining Accuracy: 0.9925 \tValidation Loss: 0.5362 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 47.7439\n",
      "fc.W_mu tensor([[ 0.4872, -0.7398,  0.0408, -0.0313],\n",
      "        [-0.6570,  0.6050, -0.0292,  0.0241]])\n",
      "fc.W_rho tensor([[-2.1687, -1.8599, -2.3659, -2.3830],\n",
      "        [-1.9796, -1.9726, -2.4573, -2.4734]])\n",
      "train\n",
      "test\n",
      "Epoch: 57 \tTraining Loss: 0.2974 \tTraining Accuracy: 0.9930 \tValidation Loss: 0.5179 \tValidation Accuracy: 0.9950 \ttrain_kl_div: 47.4159\n",
      "fc.W_mu tensor([[ 0.4949, -0.7476,  0.0352, -0.0319],\n",
      "        [-0.6651,  0.6126, -0.0287,  0.0247]])\n",
      "fc.W_rho tensor([[-2.1488, -1.8432, -2.3630, -2.3804],\n",
      "        [-1.9620, -1.9560, -2.4533, -2.4689]])\n",
      "Validation loss decreased (0.519728 --> 0.517859).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 58 \tTraining Loss: 0.2929 \tTraining Accuracy: 0.9910 \tValidation Loss: 0.5281 \tValidation Accuracy: 0.9950 \ttrain_kl_div: 47.0300\n",
      "fc.W_mu tensor([[ 0.5025, -0.7552,  0.0308, -0.0320],\n",
      "        [-0.6731,  0.6201, -0.0283,  0.0252]])\n",
      "fc.W_rho tensor([[-2.1267, -1.8252, -2.3604, -2.3774],\n",
      "        [-1.9451, -1.9407, -2.4493, -2.4645]])\n",
      "train\n",
      "test\n",
      "Epoch: 59 \tTraining Loss: 0.3106 \tTraining Accuracy: 0.9920 \tValidation Loss: 0.5001 \tValidation Accuracy: 0.9900 \ttrain_kl_div: 46.6016\n",
      "fc.W_mu tensor([[ 0.5101, -0.7629,  0.0276, -0.0317],\n",
      "        [-0.6811,  0.6276, -0.0280,  0.0255]])\n",
      "fc.W_rho tensor([[-2.1051, -1.8079, -2.3576, -2.3746],\n",
      "        [-1.9285, -1.9260, -2.4456, -2.4602]])\n",
      "Validation loss decreased (0.517859 --> 0.500076).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 60 \tTraining Loss: 0.3139 \tTraining Accuracy: 0.9870 \tValidation Loss: 0.5041 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 46.2565\n",
      "fc.W_mu tensor([[ 0.5177, -0.7707,  0.0262, -0.0312],\n",
      "        [-0.6891,  0.6352, -0.0277,  0.0257]])\n",
      "fc.W_rho tensor([[-2.0844, -1.7933, -2.3548, -2.3716],\n",
      "        [-1.9132, -1.9124, -2.4418, -2.4557]])\n",
      "train\n",
      "test\n",
      "Epoch: 61 \tTraining Loss: 0.2943 \tTraining Accuracy: 0.9885 \tValidation Loss: 0.5085 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 46.0453\n",
      "fc.W_mu tensor([[ 0.5254, -0.7784,  0.0229, -0.0306],\n",
      "        [-0.6972,  0.6428, -0.0265,  0.0258]])\n",
      "fc.W_rho tensor([[-2.0647, -1.7784, -2.3519, -2.3684],\n",
      "        [-1.9000, -1.8994, -2.4377, -2.4513]])\n",
      "train\n",
      "test\n",
      "Epoch: 62 \tTraining Loss: 0.2865 \tTraining Accuracy: 0.9935 \tValidation Loss: 0.4842 \tValidation Accuracy: 0.9900 \ttrain_kl_div: 45.8303\n",
      "fc.W_mu tensor([[ 0.5330, -0.7860,  0.0227, -0.0305],\n",
      "        [-0.7052,  0.6502, -0.0256,  0.0261]])\n",
      "fc.W_rho tensor([[-2.0463, -1.7623, -2.3495, -2.3655],\n",
      "        [-1.8851, -1.8861, -2.4338, -2.4470]])\n",
      "Validation loss decreased (0.500076 --> 0.484166).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 63 \tTraining Loss: 0.2858 \tTraining Accuracy: 0.9910 \tValidation Loss: 0.4902 \tValidation Accuracy: 0.9900 \ttrain_kl_div: 45.5690\n",
      "fc.W_mu tensor([[ 0.5405, -0.7936,  0.0252, -0.0300],\n",
      "        [-0.7131,  0.6576, -0.0251,  0.0262]])\n",
      "fc.W_rho tensor([[-2.0273, -1.7465, -2.3476, -2.3630],\n",
      "        [-1.8693, -1.8725, -2.4300, -2.4433]])\n",
      "train\n",
      "test\n",
      "Epoch: 64 \tTraining Loss: 0.2834 \tTraining Accuracy: 0.9925 \tValidation Loss: 0.4893 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 45.2847\n",
      "fc.W_mu tensor([[ 0.5480, -0.8011,  0.0277, -0.0278],\n",
      "        [-0.7209,  0.6649, -0.0246,  0.0252]])\n",
      "fc.W_rho tensor([[-2.0112, -1.7305, -2.3455, -2.3601],\n",
      "        [-1.8529, -1.8581, -2.4262, -2.4398]])\n",
      "train\n",
      "test\n",
      "Epoch: 65 \tTraining Loss: 0.2793 \tTraining Accuracy: 0.9880 \tValidation Loss: 0.5019 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 44.9833\n",
      "fc.W_mu tensor([[ 0.5554, -0.8084,  0.0274, -0.0258],\n",
      "        [-0.7287,  0.6721, -0.0235,  0.0242]])\n",
      "fc.W_rho tensor([[-1.9959, -1.7146, -2.3432, -2.3567],\n",
      "        [-1.8362, -1.8430, -2.4223, -2.4361]])\n",
      "train\n",
      "test\n",
      "Epoch: 66 \tTraining Loss: 0.2810 \tTraining Accuracy: 0.9905 \tValidation Loss: 0.4828 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 44.6502\n",
      "fc.W_mu tensor([[ 0.5628, -0.8157,  0.0271, -0.0235],\n",
      "        [-0.7365,  0.6792, -0.0226,  0.0229]])\n",
      "fc.W_rho tensor([[-1.9775, -1.6989, -2.3407, -2.3534],\n",
      "        [-1.8225, -1.8272, -2.4185, -2.4324]])\n",
      "Validation loss decreased (0.484166 --> 0.482762).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 67 \tTraining Loss: 0.2713 \tTraining Accuracy: 0.9925 \tValidation Loss: 0.4733 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 44.2972\n",
      "fc.W_mu tensor([[ 0.5701, -0.8230,  0.0252, -0.0228],\n",
      "        [-0.7441,  0.6863, -0.0215,  0.0222]])\n",
      "fc.W_rho tensor([[-1.9563, -1.6843, -2.3386, -2.3505],\n",
      "        [-1.8080, -1.8117, -2.4149, -2.4288]])\n",
      "Validation loss decreased (0.482762 --> 0.473341).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 68 \tTraining Loss: 0.2684 \tTraining Accuracy: 0.9910 \tValidation Loss: 0.4796 \tValidation Accuracy: 0.9900 \ttrain_kl_div: 43.9385\n",
      "fc.W_mu tensor([[ 0.5773, -0.8302,  0.0263, -0.0241],\n",
      "        [-0.7517,  0.6933, -0.0213,  0.0226]])\n",
      "fc.W_rho tensor([[-1.9372, -1.6704, -2.3370, -2.3479],\n",
      "        [-1.7933, -1.7956, -2.4116, -2.4255]])\n",
      "train\n",
      "test\n",
      "Epoch: 69 \tTraining Loss: 0.2628 \tTraining Accuracy: 0.9925 \tValidation Loss: 0.4881 \tValidation Accuracy: 0.9950 \ttrain_kl_div: 43.6041\n",
      "fc.W_mu tensor([[ 0.5846, -0.8373,  0.0313, -0.0252],\n",
      "        [-0.7594,  0.7001, -0.0222,  0.0227]])\n",
      "fc.W_rho tensor([[-1.9209, -1.6561, -2.3362, -2.3458],\n",
      "        [-1.7776, -1.7780, -2.4085, -2.4224]])\n",
      "train\n",
      "test\n",
      "Epoch: 70 \tTraining Loss: 0.2721 \tTraining Accuracy: 0.9895 \tValidation Loss: 0.4625 \tValidation Accuracy: 0.9950 \ttrain_kl_div: 43.2628\n",
      "fc.W_mu tensor([[ 0.5919, -0.8442,  0.0369, -0.0280],\n",
      "        [-0.7670,  0.7069, -0.0237,  0.0238]])\n",
      "fc.W_rho tensor([[-1.9038, -1.6423, -2.3355, -2.3452],\n",
      "        [-1.7634, -1.7600, -2.4057, -2.4194]])\n",
      "Validation loss decreased (0.473341 --> 0.462486).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 71 \tTraining Loss: 0.2585 \tTraining Accuracy: 0.9940 \tValidation Loss: 0.4613 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 42.9392\n",
      "fc.W_mu tensor([[ 0.5991, -0.8511,  0.0371, -0.0309],\n",
      "        [-0.7744,  0.7136, -0.0245,  0.0250]])\n",
      "fc.W_rho tensor([[-1.8875, -1.6282, -2.3345, -2.3446],\n",
      "        [-1.7471, -1.7430, -2.4033, -2.4163]])\n",
      "Validation loss decreased (0.462486 --> 0.461295).  Saving model ...\n",
      "train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Epoch: 72 \tTraining Loss: 0.2613 \tTraining Accuracy: 0.9880 \tValidation Loss: 0.4484 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 42.5705\n",
      "fc.W_mu tensor([[ 0.6062, -0.8580,  0.0350, -0.0331],\n",
      "        [-0.7819,  0.7203, -0.0251,  0.0261]])\n",
      "fc.W_rho tensor([[-1.8712, -1.6143, -2.3332, -2.3444],\n",
      "        [-1.7301, -1.7273, -2.4007, -2.4129]])\n",
      "Validation loss decreased (0.461295 --> 0.448402).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 73 \tTraining Loss: 0.2691 \tTraining Accuracy: 0.9890 \tValidation Loss: 0.4632 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 42.2176\n",
      "fc.W_mu tensor([[ 0.6133, -0.8648,  0.0322, -0.0343],\n",
      "        [-0.7893,  0.7270, -0.0257,  0.0269]])\n",
      "fc.W_rho tensor([[-1.8562, -1.6011, -2.3319, -2.3442],\n",
      "        [-1.7150, -1.7119, -2.3982, -2.4096]])\n",
      "train\n",
      "test\n",
      "Epoch: 74 \tTraining Loss: 0.2553 \tTraining Accuracy: 0.9920 \tValidation Loss: 0.4488 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 41.8935\n",
      "fc.W_mu tensor([[ 0.6202, -0.8719,  0.0308, -0.0349],\n",
      "        [-0.7965,  0.7338, -0.0266,  0.0275]])\n",
      "fc.W_rho tensor([[-1.8387, -1.5892, -2.3308, -2.3439],\n",
      "        [-1.6977, -1.6983, -2.3964, -2.4069]])\n",
      "train\n",
      "test\n",
      "Epoch: 75 \tTraining Loss: 0.2543 \tTraining Accuracy: 0.9900 \tValidation Loss: 0.4607 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 41.6007\n",
      "fc.W_mu tensor([[ 0.6270, -0.8789,  0.0301, -0.0348],\n",
      "        [-0.8036,  0.7407, -0.0275,  0.0279]])\n",
      "fc.W_rho tensor([[-1.8232, -1.5780, -2.3299, -2.3437],\n",
      "        [-1.6811, -1.6857, -2.3943, -2.4041]])\n",
      "train\n",
      "test\n",
      "Epoch: 76 \tTraining Loss: 0.2498 \tTraining Accuracy: 0.9930 \tValidation Loss: 0.4330 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 41.3155\n",
      "fc.W_mu tensor([[ 0.6338, -0.8859,  0.0257, -0.0347],\n",
      "        [-0.8107,  0.7475, -0.0272,  0.0285]])\n",
      "fc.W_rho tensor([[-1.8066, -1.5669, -2.3285, -2.3426],\n",
      "        [-1.6636, -1.6733, -2.3919, -2.4014]])\n",
      "Validation loss decreased (0.448402 --> 0.432984).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 77 \tTraining Loss: 0.2538 \tTraining Accuracy: 0.9915 \tValidation Loss: 0.4466 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 41.0218\n",
      "fc.W_mu tensor([[ 0.6406, -0.8928,  0.0230, -0.0342],\n",
      "        [-0.8178,  0.7543, -0.0268,  0.0289]])\n",
      "fc.W_rho tensor([[-1.7913, -1.5554, -2.3274, -2.3414],\n",
      "        [-1.6473, -1.6617, -2.3896, -2.3987]])\n",
      "train\n",
      "test\n",
      "Epoch: 78 \tTraining Loss: 0.2568 \tTraining Accuracy: 0.9910 \tValidation Loss: 0.4311 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 40.7542\n",
      "fc.W_mu tensor([[ 0.6474, -0.8997,  0.0198, -0.0329],\n",
      "        [-0.8249,  0.7610, -0.0258,  0.0289]])\n",
      "fc.W_rho tensor([[-1.7778, -1.5439, -2.3259, -2.3403],\n",
      "        [-1.6302, -1.6512, -2.3873, -2.3959]])\n",
      "Validation loss decreased (0.432984 --> 0.431142).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 79 \tTraining Loss: 0.2641 \tTraining Accuracy: 0.9905 \tValidation Loss: 0.4297 \tValidation Accuracy: 0.9900 \ttrain_kl_div: 40.5300\n",
      "fc.W_mu tensor([[ 0.6543, -0.9068,  0.0187, -0.0315],\n",
      "        [-0.8320,  0.7679, -0.0249,  0.0287]])\n",
      "fc.W_rho tensor([[-1.7661, -1.5337, -2.3249, -2.3386],\n",
      "        [-1.6142, -1.6421, -2.3848, -2.3928]])\n",
      "Validation loss decreased (0.431142 --> 0.429719).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 80 \tTraining Loss: 0.2469 \tTraining Accuracy: 0.9935 \tValidation Loss: 0.4219 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 40.4161\n",
      "fc.W_mu tensor([[ 0.6611, -0.9138,  0.0216, -0.0298],\n",
      "        [-0.8391,  0.7748, -0.0244,  0.0282]])\n",
      "fc.W_rho tensor([[-1.7542, -1.5235, -2.3242, -2.3373],\n",
      "        [-1.5994, -1.6342, -2.3824, -2.3895]])\n",
      "Validation loss decreased (0.429719 --> 0.421949).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 81 \tTraining Loss: 0.2388 \tTraining Accuracy: 0.9920 \tValidation Loss: 0.4234 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 40.3161\n",
      "fc.W_mu tensor([[ 0.6678, -0.9208,  0.0280, -0.0282],\n",
      "        [-0.8461,  0.7817, -0.0248,  0.0276]])\n",
      "fc.W_rho tensor([[-1.7424, -1.5128, -2.3239, -2.3356],\n",
      "        [-1.5830, -1.6271, -2.3805, -2.3862]])\n",
      "train\n",
      "test\n",
      "Epoch: 82 \tTraining Loss: 0.2459 \tTraining Accuracy: 0.9900 \tValidation Loss: 0.4192 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 40.2116\n",
      "fc.W_mu tensor([[ 0.6745, -0.9277,  0.0337, -0.0265],\n",
      "        [-0.8531,  0.7884, -0.0252,  0.0268]])\n",
      "fc.W_rho tensor([[-1.7331, -1.5018, -2.3235, -2.3342],\n",
      "        [-1.5669, -1.6201, -2.3786, -2.3831]])\n",
      "Validation loss decreased (0.421949 --> 0.419185).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 83 \tTraining Loss: 0.2394 \tTraining Accuracy: 0.9920 \tValidation Loss: 0.4191 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 40.1242\n",
      "fc.W_mu tensor([[ 0.6811, -0.9346,  0.0365, -0.0257],\n",
      "        [-0.8601,  0.7951, -0.0255,  0.0262]])\n",
      "fc.W_rho tensor([[-1.7227, -1.4911, -2.3229, -2.3327],\n",
      "        [-1.5511, -1.6126, -2.3767, -2.3801]])\n",
      "Validation loss decreased (0.419185 --> 0.419142).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 84 \tTraining Loss: 0.2212 \tTraining Accuracy: 0.9925 \tValidation Loss: 0.4275 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 40.0006\n",
      "fc.W_mu tensor([[ 0.6877, -0.9412,  0.0378, -0.0261],\n",
      "        [-0.8670,  0.8016, -0.0260,  0.0262]])\n",
      "fc.W_rho tensor([[-1.7087, -1.4795, -2.3220, -2.3314],\n",
      "        [-1.5362, -1.6039, -2.3748, -2.3774]])\n",
      "train\n",
      "test\n",
      "Epoch: 85 \tTraining Loss: 0.2453 \tTraining Accuracy: 0.9900 \tValidation Loss: 0.4243 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 39.7826\n",
      "fc.W_mu tensor([[ 0.6942, -0.9478,  0.0358, -0.0275],\n",
      "        [-0.8738,  0.8080, -0.0262,  0.0266]])\n",
      "fc.W_rho tensor([[-1.6945, -1.4683, -2.3207, -2.3311],\n",
      "        [-1.5219, -1.5944, -2.3728, -2.3748]])\n",
      "train\n",
      "test\n",
      "Epoch: 86 \tTraining Loss: 0.2149 \tTraining Accuracy: 0.9940 \tValidation Loss: 0.4075 \tValidation Accuracy: 0.9900 \ttrain_kl_div: 39.5652\n",
      "fc.W_mu tensor([[ 0.7006, -0.9544,  0.0294, -0.0290],\n",
      "        [-0.8805,  0.8144, -0.0255,  0.0269]])\n",
      "fc.W_rho tensor([[-1.6798, -1.4575, -2.3189, -2.3313],\n",
      "        [-1.5064, -1.5839, -2.3706, -2.3721]])\n",
      "Validation loss decreased (0.419142 --> 0.407548).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 87 \tTraining Loss: 0.2299 \tTraining Accuracy: 0.9930 \tValidation Loss: 0.4201 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 39.2700\n",
      "fc.W_mu tensor([[ 0.7068, -0.9610,  0.0209, -0.0295],\n",
      "        [-0.8870,  0.8208, -0.0241,  0.0269]])\n",
      "fc.W_rho tensor([[-1.6678, -1.4462, -2.3171, -2.3317],\n",
      "        [-1.4877, -1.5744, -2.3685, -2.3695]])\n",
      "train\n",
      "test\n",
      "Epoch: 88 \tTraining Loss: 0.2382 \tTraining Accuracy: 0.9920 \tValidation Loss: 0.4087 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 39.0020\n",
      "fc.W_mu tensor([[ 0.7132, -0.9675,  0.0147, -0.0307],\n",
      "        [-0.8937,  0.8272, -0.0228,  0.0273]])\n",
      "fc.W_rho tensor([[-1.6581, -1.4351, -2.3153, -2.3318],\n",
      "        [-1.4710, -1.5658, -2.3664, -2.3670]])\n",
      "train\n",
      "test\n",
      "Epoch: 89 \tTraining Loss: 0.2150 \tTraining Accuracy: 0.9935 \tValidation Loss: 0.4025 \tValidation Accuracy: 0.9900 \ttrain_kl_div: 38.8139\n",
      "fc.W_mu tensor([[ 0.7195, -0.9740,  0.0137, -0.0325],\n",
      "        [-0.9004,  0.8334, -0.0221,  0.0282]])\n",
      "fc.W_rho tensor([[-1.6461, -1.4233, -2.3146, -2.3320],\n",
      "        [-1.4558, -1.5564, -2.3646, -2.3647]])\n",
      "Validation loss decreased (0.407548 --> 0.402463).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 90 \tTraining Loss: 0.2301 \tTraining Accuracy: 0.9890 \tValidation Loss: 0.3951 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 38.6009\n",
      "fc.W_mu tensor([[ 0.7259, -0.9802,  0.0177, -0.0341],\n",
      "        [-0.9071,  0.8395, -0.0222,  0.0291]])\n",
      "fc.W_rho tensor([[-1.6383, -1.4117, -2.3148, -2.3321],\n",
      "        [-1.4406, -1.5448, -2.3630, -2.3624]])\n",
      "Validation loss decreased (0.402463 --> 0.395069).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 91 \tTraining Loss: 0.2269 \tTraining Accuracy: 0.9915 \tValidation Loss: 0.3858 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 38.4199\n",
      "fc.W_mu tensor([[ 0.7323, -0.9864,  0.0250, -0.0343],\n",
      "        [-0.9139,  0.8455, -0.0230,  0.0295]])\n",
      "fc.W_rho tensor([[-1.6317, -1.4008, -2.3155, -2.3317],\n",
      "        [-1.4256, -1.5319, -2.3613, -2.3600]])\n",
      "Validation loss decreased (0.395069 --> 0.385785).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 92 \tTraining Loss: 0.2056 \tTraining Accuracy: 0.9940 \tValidation Loss: 0.4072 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 38.2304\n",
      "fc.W_mu tensor([[ 0.7386, -0.9925,  0.0295, -0.0334],\n",
      "        [-0.9205,  0.8514, -0.0232,  0.0295]])\n",
      "fc.W_rho tensor([[-1.6206, -1.3892, -2.3158, -2.3307],\n",
      "        [-1.4109, -1.5189, -2.3596, -2.3579]])\n",
      "train\n",
      "test\n",
      "Epoch: 93 \tTraining Loss: 0.2238 \tTraining Accuracy: 0.9920 \tValidation Loss: 0.3845 \tValidation Accuracy: 0.9900 \ttrain_kl_div: 37.9634\n",
      "fc.W_mu tensor([[ 0.7449, -0.9985,  0.0330, -0.0316],\n",
      "        [-0.9272,  0.8573, -0.0236,  0.0290]])\n",
      "fc.W_rho tensor([[-1.6090, -1.3777, -2.3164, -2.3294],\n",
      "        [-1.3983, -1.5053, -2.3582, -2.3556]])\n",
      "Validation loss decreased (0.385785 --> 0.384514).  Saving model ...\n",
      "train\n",
      "test\n",
      "Epoch: 94 \tTraining Loss: 0.2281 \tTraining Accuracy: 0.9915 \tValidation Loss: 0.3870 \tValidation Accuracy: 0.9900 \ttrain_kl_div: 37.7220\n",
      "fc.W_mu tensor([[ 0.7513, -1.0046,  0.0338, -0.0289],\n",
      "        [-0.9340,  0.8631, -0.0239,  0.0280]])\n",
      "fc.W_rho tensor([[-1.5993, -1.3674, -2.3166, -2.3285],\n",
      "        [-1.3877, -1.4910, -2.3567, -2.3537]])\n",
      "train\n",
      "test\n",
      "Epoch: 95 \tTraining Loss: 0.2359 \tTraining Accuracy: 0.9880 \tValidation Loss: 0.4139 \tValidation Accuracy: 0.9900 \ttrain_kl_div: 37.5520\n",
      "fc.W_mu tensor([[ 0.7578, -1.0106,  0.0355, -0.0270],\n",
      "        [-0.9409,  0.8690, -0.0250,  0.0273]])\n",
      "fc.W_rho tensor([[-1.5908, -1.3587, -2.3173, -2.3278],\n",
      "        [-1.3808, -1.4765, -2.3551, -2.3522]])\n",
      "train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Epoch: 96 \tTraining Loss: 0.2177 \tTraining Accuracy: 0.9935 \tValidation Loss: 0.3962 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 37.4838\n",
      "fc.W_mu tensor([[ 0.7644, -1.0166,  0.0328, -0.0254],\n",
      "        [-0.9479,  0.8748, -0.0253,  0.0266]])\n",
      "fc.W_rho tensor([[-1.5833, -1.3492, -2.3174, -2.3266],\n",
      "        [-1.3765, -1.4619, -2.3536, -2.3507]])\n",
      "train\n",
      "test\n",
      "Epoch: 97 \tTraining Loss: 0.2291 \tTraining Accuracy: 0.9880 \tValidation Loss: 0.3868 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 37.4217\n",
      "fc.W_mu tensor([[ 0.7712, -1.0225,  0.0286, -0.0240],\n",
      "        [-0.9550,  0.8805, -0.0254,  0.0258]])\n",
      "fc.W_rho tensor([[-1.5747, -1.3388, -2.3169, -2.3256],\n",
      "        [-1.3762, -1.4479, -2.3521, -2.3494]])\n",
      "train\n",
      "test\n",
      "Epoch: 98 \tTraining Loss: 0.2004 \tTraining Accuracy: 0.9945 \tValidation Loss: 0.3889 \tValidation Accuracy: 0.9925 \ttrain_kl_div: 37.3734\n",
      "fc.W_mu tensor([[ 0.7777, -1.0283,  0.0228, -0.0236],\n",
      "        [-0.9619,  0.8862, -0.0249,  0.0254]])\n",
      "fc.W_rho tensor([[-1.5658, -1.3271, -2.3163, -2.3248],\n",
      "        [-1.3723, -1.4348, -2.3504, -2.3485]])\n",
      "train\n",
      "test\n",
      "Epoch: 99 \tTraining Loss: 0.2081 \tTraining Accuracy: 0.9915 \tValidation Loss: 0.3832 \tValidation Accuracy: 0.9900 \ttrain_kl_div: 37.2584\n",
      "fc.W_mu tensor([[ 0.7841, -1.0341,  0.0185, -0.0231],\n",
      "        [-0.9687,  0.8918, -0.0243,  0.0247]])\n",
      "fc.W_rho tensor([[-1.5554, -1.3142, -2.3159, -2.3247],\n",
      "        [-1.3678, -1.4232, -2.3489, -2.3477]])\n",
      "Validation loss decreased (0.384514 --> 0.383158).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "device=\"cpu\"\n",
    "Images=np.load('../../data/orthogonal_var3.npy',allow_pickle=True)\n",
    "net_type=\"Net\"\n",
    "label0=Images.item().get('[0]')\n",
    "label1=Images.item().get('[1]')\n",
    "\n",
    "train_data=[]\n",
    "reduction_num=1000\n",
    "for i in range(reduction_num):\n",
    "    train_data.append([label0[i],0])\n",
    "for i in range(reduction_num):\n",
    "    train_data.append([label1[i],1])\n",
    "test_label0=label0[1001:1300]\n",
    "test_label1=label1[1001:1300]\n",
    "valid_label0=label0[1400:1600]\n",
    "valid_label1=label1[1400:1600]\n",
    "\n",
    "test_data=[]\n",
    "for i in range(200):\n",
    "    test_data.append([test_label0[i],0])\n",
    "for i in range(200):\n",
    "    test_data.append([test_label1[i],1])\n",
    "\n",
    "valid_data=[]\n",
    "for i in range(200):\n",
    "    valid_data.append([valid_label0[i],0])\n",
    "for i in range(200):\n",
    "    valid_data.append([valid_label1[i],1])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=reduction_num,drop_last = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=400, drop_last=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=400, drop_last=True)\n",
    "\n",
    "net = getModel(net_type, priors).to(device)\n",
    "\n",
    "ckpt_dir = f'checkpoints/var3/bayesian'\n",
    "ckpt_name = f'checkpoints/var3/bayesian/model_{net_type}_{layer_type}_{activation_type}.pt'\n",
    "\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir, exist_ok=True)\n",
    "\n",
    "criterion = ELBO(reduction_num*2).to(device)\n",
    "optimizer = Adam(net.parameters(), lr=lr_start)\n",
    "#lr_sched = lr_scheduler.ReduceLROnPlateau(optimizer, patience=6, verbose=True)\n",
    "valid_loss_max = np.Inf\n",
    "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "    print('train')\n",
    "    train_loss, train_acc, train_kl = train_model(net, optimizer, criterion, train_loader, num_ens=train_ens, beta_type=beta_type, epoch=epoch, num_epochs=n_epochs)\n",
    "    print('test')\n",
    "    valid_loss, valid_acc = validate_model(net, criterion, valid_loader, num_ens=valid_ens, beta_type=beta_type, epoch=epoch, num_epochs=n_epochs)\n",
    "    #lr_sched.step(valid_loss)\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.4f} \\tTraining Accuracy: {:.4f} \\tValidation Loss: {:.4f} \\tValidation Accuracy: {:.4f} \\ttrain_kl_div: {:.4f}'.format(\n",
    "        epoch, train_loss, train_acc, valid_loss, valid_acc, train_kl))\n",
    "\n",
    "    for name, param in net.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(name, param.data)\n",
    "\n",
    "    # save model if validation accuracy has increased\n",
    "    if valid_loss <= valid_loss_max:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_max, valid_loss))\n",
    "        torch.save(net.state_dict(), ckpt_name)\n",
    "        valid_loss_max = valid_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian",
   "language": "python",
   "name": "bayesian"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
